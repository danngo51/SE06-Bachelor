import joblib
import os
import pathlib
import pandas as pd
import numpy as np
from typing import Dict, List, Optional
from dataclasses import dataclass

@dataclass
class ZonePaths:
    """Class for managing file paths for a specific zone"""
    # Data paths
    prediction_data: pathlib.Path
    training_data: pathlib.Path
    
    # Regime model paths
    regime_dir: pathlib.Path
    
    @property
    def prediction_data_str(self) -> str:
        """Get prediction data path as string"""
        return str(self.prediction_data)
    
    @property
    def training_data_str(self) -> str:
        """Get training data path as string"""
        return str(self.training_data)
    
    @property
    def normal_model_path(self) -> str:
        """Get path to normal regime model"""
        return str(self.regime_dir / "model_normal.pkl")
    
    @property
    def spike_model_path(self) -> str:
        """Get path to spike regime model"""
        return str(self.regime_dir / "model_spike.pkl")
    
    def check_missing_files(self) -> List[str]:
        """Check for missing required model files"""
        missing_files = []
        
        if not os.path.exists(self.normal_model_path):
            missing_files.append(f"normal regime model: {self.normal_model_path}")
        
        if not os.path.exists(self.spike_model_path):
            missing_files.append(f"spike regime model: {self.spike_model_path}")
            
        return missing_files

class PredictionService:
    # Define paths once for reuse
    ROOT_PATH = pathlib.Path(__file__).parent.parent.parent  # MLs directory
    ML_MODELS_DIR = ROOT_PATH / "ml_models"
    DATA_DIR = ML_MODELS_DIR / "data"
    
    # Dictionary to store zone paths (cached for reuse)
    _zone_paths_cache: Dict[str, ZonePaths] = {}
    
    def __init__(self, mapCode="DK1"):
        self.mapCode = mapCode
        self.threshold = None
        self.normal_model = None
        self.spike_model = None
        self._load_model()
    
    @staticmethod
    def get_zone_paths(mapCode: str) -> ZonePaths:
        """
        Get all path configurations for a specific zone
        
        Args:
            mapCode: Zone code (e.g., 'DK1')
        
        Returns:
            ZonePaths object with all path configurations for the zone
        """
        # Check if we have already computed paths for this zone
        if mapCode in PredictionService._zone_paths_cache:
            return PredictionService._zone_paths_cache[mapCode]
        
        # Create new ZonePaths object for this zone
        data_dir = PredictionService.DATA_DIR / mapCode
        paths = ZonePaths(
            # Data paths
            prediction_data=data_dir / f"{mapCode}_full_data_2025.csv",
            training_data=data_dir / f"{mapCode}_full_data_2018_2024.csv",
            
            # Regime model paths
            regime_dir=data_dir / "regime_models",
        )
        
        # Cache the paths for future use
        PredictionService._zone_paths_cache[mapCode] = paths
        
        return paths
    
    def _load_model(self):
        # Get paths for this zone
        zone_paths = self.get_zone_paths(self.mapCode)
        
        # Check if any required model files are missing
        missing_files = zone_paths.check_missing_files()
        if missing_files:
            raise FileNotFoundError(f"Missing model files: {', '.join(missing_files)}")
        
        # Load regime models
        self.normal_model = joblib.load(zone_paths.normal_model_path)
        self.spike_model = joblib.load(zone_paths.spike_model_path)
        
        # Load dataset to determine threshold
        dataset = pd.read_csv(zone_paths.training_data_str)
        self.threshold = dataset['Electricity_price_MWh'].quantile(0.90)
      def predict(self, data):
        """
        Make predictions using the regime-based model
        
        Args:
            data: DataFrame with features
            
        Returns:
            Series with predictions
        """
        # Determine regime based on EP_lag_1
        is_spike = data['EP_lag_1'] > self.threshold
        
        # Initialize prediction array with NaNs
        prediction = pd.Series(index=data.index, dtype=float)
        
        # Apply appropriate model based on regime
        if not is_spike.empty and is_spike.any():
            prediction.loc[is_spike] = self.spike_model.predict(data.loc[is_spike])
        
        if not is_spike.empty and (~is_spike).any():
            prediction.loc[~is_spike] = self.normal_model.predict(data.loc[~is_spike])
        
        return prediction
      def status(self) -> Dict:
        """Return service status"""
        return {"status": "Prediction service running", "model": "XGBoost regime model"}
        
    def predict_from_file(self, date_str: str = None):
        """
        Load data from file and make predictions for a specific date
        
        Args:
            date_str: Date string in format 'YYYY-MM-DD'
            
        Returns:
            DataFrame with predictions
        """
        # Get paths for this zone
        zone_paths = self.get_zone_paths(self.mapCode)
        
        # Load prediction data
        df = pd.read_csv(zone_paths.prediction_data_str, parse_dates=['date'])
        
        # Add engineered features needed for prediction
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
        df['price_roll_3h'] = df['Electricity_price_MWh'].shift(1).rolling(3, min_periods=1).mean()
        df['load_roll_6h'] = df['DAHTL_TotalLoadValue'].shift(1).rolling(6, min_periods=1).mean()
        df['gas_x_load'] = df['Natural_Gas_price_EUR'] * df['DAHTL_TotalLoadValue']
        df['EP_lag_1'] = df['Electricity_price_MWh'].shift(1)
        df = df.dropna()
        
        # Filter by date if provided
        if date_str:
            df = df.loc[df['date'].dt.strftime('%Y-%m-%d') == date_str].copy()
        
        if df.empty:
            raise ValueError(f"No data found for date: {date_str}")
        
        # Prepare feature matrix
        features = [c for c in df.columns if c not in ['date', 'Electricity_price_MWh']]
        X = df[features]
        
        # Make predictions
        df['Predicted'] = self.predict(X)
        df['True'] = df['Electricity_price_MWh']
        df['Pct_of_True'] = df['Predicted'] / df['True'] * 100
        
        return df[['date', 'hour', 'True', 'Predicted', 'Pct_of_True']]
